{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "079347e5",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"text-align: Center\">Documents by Context Category</div>\n",
    "<div style=\"text-align: Center\">From Scratch</div>\n",
    "<div style=\"text-align: Center\">Pawel Sobieralski, 2022 </div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b535507",
   "metadata": {},
   "source": [
    "# Solution Design - From Scratch\n",
    "\n",
    "Determine to which context category document belongs\n",
    "\n",
    "\n",
    "## Description:\n",
    "This is a prototype solution built from basic numerical functions. \n",
    "The solution builds two context vectors in vacabulary space - one for the training corpus and one for an unseen document. Then it compares distance between these vectors in a given subset of dimensions. The subset dimensions corespond to context category.\n",
    "The training corpus vector in given dimensions (context 1) will be silmiliar to the new document vector if true document context is 1.\n",
    "The training corpus vector in given dimensions (context 2) will be disimilar to the new document vector if true document context is 1.\n",
    "\n",
    "Another approach I considered is use linear relationships in doc2vec - see my other workbook.\n",
    "\n",
    "Extra python code introduces interface and class style coding for this solution.\n",
    "\n",
    "## Example usage:\n",
    " \n",
    "<strong>Preprocess</strong>  \n",
    "train_doc = se_process_document(train_corpus)  \n",
    "test_doc = se_process_document(test_document)\n",
    "\n",
    "<strong>Build vector space</strong>  \n",
    "vocab_dict = se_build_vocabulary(train_doc)\n",
    "\n",
    "<strong>Build context vectors</strong>  \n",
    "train_vector = se_build_context(train_doc,vocab_dict)\n",
    "test_vector = se_build_context(test_doc,vocab_dict)\n",
    "\n",
    "<strong>Compare documents in given category</strong>  \n",
    "se_compare_by_context(train_vector, test_vector, context1)\n",
    "\n",
    "## Files list\n",
    "\n",
    "This document - Jupiter Notebook with solution prototype  \n",
    "context_category.py - Python class implementation\n",
    "\n",
    "utils.py - Utilities  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec2f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Python\")\n",
    "\n",
    "# Utilities\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411139d8",
   "metadata": {},
   "source": [
    "# Sample Corpus\n",
    "These documents are assumed to be all money laundering documents. While the sentences may not necessarily make sense to humans - they have properties required for this project - corpus with multiple context. \n",
    "\n",
    "First 5 sentences [allegations,accusations,charges]\n",
    "\n",
    "Last 4 sentences [conviction,sentencing]\n",
    "\n",
    "Also - unseen before document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9497f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [\n",
    "    \"Human machine interface for lab abc allegations applications\",\n",
    "    \"A survey of user opinion of allegations accusations charges time\",\n",
    "    \"The EPS user interface management accusations\",\n",
    "    \"Accusations and human accusations engineering testing of EPS\",\n",
    "    \"Relation of user perceived charges time to error measurement\",\n",
    "    \"The generation of random binary unordered conviction\",\n",
    "    \"The intersection sentencing of paths in conviction\",\n",
    "    \"Sentencing minors IV Widths of conviction and well quasi ordering\",\n",
    "    \"Sentencing minors A survey\",\n",
    "]\n",
    "\n",
    "context1 = ['allegations','accusations','charges']\n",
    "context2 = ['conviction','sentencing']\n",
    "\n",
    "#Unseen before document\n",
    "#It belongs to context 1 but it does not contain any keyword from context 1\n",
    "test_document = [\"Machine management interface\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fdeb9",
   "metadata": {},
   "source": [
    "# Process Document\n",
    "Tokenize into individual words, remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b272e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human',\n",
       " 'machine',\n",
       " 'interface',\n",
       " 'lab',\n",
       " 'abc',\n",
       " 'allegations',\n",
       " 'applications',\n",
       " 'survey',\n",
       " 'user',\n",
       " 'opinion']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def se_process_document(corpus_doc):\n",
    "    \n",
    "    proc_doc = list(map(utils.process_document,corpus_doc)) \n",
    "    tokens_flat_list = [item for sublist in proc_doc for item in sublist]\n",
    "    return tokens_flat_list\n",
    "\n",
    "train_doc = se_process_document(train_corpus)\n",
    "train_doc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda1e74",
   "metadata": {},
   "source": [
    "# Build Vector Space\n",
    "Builds sorted vocabulary and indexe words to process faster later.\n",
    "\n",
    "The same vector space used throughtout all training and test/validations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cb2009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def se_build_vocabulary(tc):\n",
    "\n",
    "    vocab = list(set(tc))\n",
    "    vocab.sort()\n",
    "    \n",
    "    vocab_dict = {}\n",
    "    for index, word in enumerate(vocab):\n",
    "        vocab_dict[word] = index\n",
    "        \n",
    "    return vocab_dict\n",
    "\n",
    "vocab_dict = se_build_vocabulary(train_doc)\n",
    "vocab_dict['allegations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b414f",
   "metadata": {},
   "source": [
    "# Build Context\n",
    "Build context in the co-occurance matrix for a given corpora and vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384644a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>accusations</th>\n",
       "      <th>allegations</th>\n",
       "      <th>applications</th>\n",
       "      <th>binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abc</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accusations</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allegations</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applications</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   abc  accusations  allegations  applications  binary\n",
       "abc           0.000000     0.000000     0.019231      0.019231     0.0\n",
       "accusations   0.000000     0.076923     0.019231      0.000000     0.0\n",
       "allegations   0.019231     0.019231     0.000000      0.019231     0.0\n",
       "applications  0.019231     0.000000     0.019231      0.000000     0.0\n",
       "binary        0.000000     0.000000     0.000000      0.000000     0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def se_build_context(corpus_list, vocab_dict, window):\n",
    "\n",
    "    co_occurrence_vectors = pd.DataFrame(\n",
    "        np.zeros([len(vocab_dict), len(vocab_dict)]),\n",
    "        index = vocab_dict.keys(),\n",
    "        columns = vocab_dict.keys()\n",
    "    )\n",
    "    \n",
    "    for index, element in enumerate(corpus_list):\n",
    "        \n",
    "        start = 0 if index - window < 0 else index - window\n",
    "        finish = len(corpus_list) if index+2 > len(corpus_list) else index+3\n",
    "        \n",
    "        context = corpus_list[start:index] + corpus_list[index+1:finish]\n",
    "        for word in context:\n",
    "            \n",
    "            co_occurrence_vectors.loc[element, word] = (\n",
    "                co_occurrence_vectors.loc[element, word]+1\n",
    "            )\n",
    "            \n",
    "    return co_occurrence_vectors/len(corpus_list) #Scale\n",
    "\n",
    "train_vector = se_build_context(train_doc,vocab_dict, 2)\n",
    "train_vector.iloc[0:5,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7414fd48",
   "metadata": {},
   "source": [
    "# Measure of Similiarity - Pair Wise\n",
    " Example of top words by pair wise similarity, for example charges is close to accusations.\n",
    " This is just for reaserch, the solution is using vector similiarity not pair wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e36f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charges        1.000000\n",
       "user           0.507093\n",
       "time           0.500000\n",
       "measurement    0.474342\n",
       "opinion        0.474342\n",
       "relation       0.474342\n",
       "perceived      0.474342\n",
       "eps            0.400000\n",
       "management     0.387298\n",
       "accusations    0.368932\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_words = pd.DataFrame(\n",
    "    \n",
    "    cosine_similarity(train_vector),\n",
    "    columns = vocab_dict.keys(),\n",
    "    index = vocab_dict.keys()\n",
    "\n",
    ")\n",
    "\n",
    "similarity_words.loc['charges'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d48d6",
   "metadata": {},
   "source": [
    "# Measure of Similiarity - Vector Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95254aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def se_cosine_similarity(v1,v2):\n",
    "    \n",
    "    denominator = la.norm(v1) * la.norm(v2)\n",
    "    \n",
    "    if denominator > 0:\n",
    "        return v1.dot(v2) / denominator\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "v = np.array([40,11,4,11,14]) #Test\n",
    "\n",
    "se_cosine_similarity(v,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdca23ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36893239368631087"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_cosine_similarity(np.array(train_vector['charges']),np.array(train_vector['accusations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d068a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.273861278752583"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test OK\n",
    "se_cosine_similarity(np.array(train_vector['charges']),np.array(train_vector['human']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421253e",
   "metadata": {},
   "source": [
    "# Document Unseen Before\n",
    "Builds context from unseen document in the exactly same vector space as training corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40142bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>accusations</th>\n",
       "      <th>allegations</th>\n",
       "      <th>applications</th>\n",
       "      <th>binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accusations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allegations</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applications</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              abc  accusations  allegations  applications  binary\n",
       "abc           0.0          0.0          0.0           0.0     0.0\n",
       "accusations   0.0          0.0          0.0           0.0     0.0\n",
       "allegations   0.0          0.0          0.0           0.0     0.0\n",
       "applications  0.0          0.0          0.0           0.0     0.0\n",
       "binary        0.0          0.0          0.0           0.0     0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = se_process_document(test_document)\n",
    "test_vector = se_build_context(test_doc,vocab_dict,2)\n",
    "test_vector.iloc[0:5,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21f313",
   "metadata": {},
   "source": [
    "# Compare Documents by Context\n",
    "Compares different documents by given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d34c19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_compare_by_context(doc1, doc2, dimensions):\n",
    "    \n",
    "    angle = 0.0\n",
    "    for i, d in enumerate(dimensions):\n",
    "        \n",
    "        #Reverse cosine to radians to get avg\n",
    "        angle += np.arccos(se_cosine_similarity(np.array(doc1[d]), np.array(doc2[d])))\n",
    "        angle = angle / len(dimensions)\n",
    "        \n",
    "        return (dimensions,np.cos(angle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca36bcc",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384be436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence is in allegations,accusations,charges context\n",
      "Score: 0.866\n"
     ]
    }
   ],
   "source": [
    "def se_get_context_score(train_vector, test_vector, context_list):\n",
    "    \n",
    "    return round(se_compare_by_context(train_vector, test_vector, context_list)[1],3)\n",
    "\n",
    "context1 = ('allegations','accusations','charges')\n",
    "context2 = ('conviction','sentencing')\n",
    "\n",
    "doc_by_context = {}\n",
    "doc_by_context[context1] = se_get_context_score(train_vector, test_vector, context1)\n",
    "doc_by_context[context2] = se_get_context_score(train_vector, test_vector, context2)\n",
    "\n",
    "if doc_by_context[context1] > doc_by_context[context2]:\n",
    "    print('Test sentence is in ' + ','.join(context1) + ' context')\n",
    "    print('Score: ' + str(doc_by_context[context1]))\n",
    "else:\n",
    "    print('Test sentence is in ' + ','.join(context2) + ' context')\n",
    "    print('Score: ' + str(doc_by_context[context2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
